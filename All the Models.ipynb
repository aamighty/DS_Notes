{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Cross Validation](#cross val)  \n",
    "[Linear Regression](#lin reg)  \n",
    "[Evaluating Classifiers](#eval)  \n",
    "[Logistic Regression](#logreg)  \n",
    "[K-Nearest Neighbors](#knn)  \n",
    "[Support Vector Machines](#svm)  \n",
    "[Classification & Regression Trees](#carts)  \n",
    "[Ensemble Methods](#ensemble)  \n",
    "[Classification Review](#class review)  \n",
    "[Boosting](#boosting)  \n",
    "[Clustering](#clustering)  \n",
    "[K-Means](#kmeans)  \n",
    "[DBSCAN](#dbscan)  \n",
    "[Hierarchical Clustering](#hierarchy)  \n",
    "[Time Series & Datetime](#time)  \n",
    "[Neural Networks](#neural nets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='cross val'></a>\n",
    "# Cross Validation\n",
    "---\n",
    "<span style=\"color:green\"> Error </span> - Degree to which model's predictions diverge from known actual value \n",
    "$$\\epsilon = \\frac{Y_i}{\\hat {Y}_i}$$\n",
    "## Bias Variance Trade Off\n",
    "<span style=\"color:green\"> Bias </span> - A model has it if it makes assumtpions about what the data should look like but misses the mark  \n",
    "<span style=\"color:green\"> Variance </span> - A model that has mistaken unique or weird parts of the dataset for broader, predictive trends. Predicts data it has seen well but new data very poorly   \n",
    "$$\\frac{\\delta Bias}{\\delta Complexity} = -\\frac{\\delta Variance}{\\delta Complexity} $$\n",
    "For a small change in complexity of model there is an inverse and equal chance between bias & variance\n",
    "\n",
    "Complexity $\\uparrow$  $\\Rightarrow$ Variance $\\uparrow$ Bias $\\downarrow$  \n",
    "Complexity $\\downarrow$  $\\Rightarrow$ Variance $\\downarrow$ Bias $\\uparrow$\n",
    "\n",
    "## K-Fold Cross Validation\n",
    "Expands single train test split and expands to multiple tests across train tests splits of data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='lin reg'></a>\n",
    "# Linear Regression \n",
    "---\n",
    "\n",
    "### $O(np^2)$\n",
    "\n",
    "Linear relationship between the dependent and independent variables where X and Y are continuous  \n",
    "Continuous Variables => numerical\n",
    "    - Continuous -> fractional/irrational\n",
    "    - Discrete -> whole numbers  \n",
    "    \n",
    "## Assumptions\n",
    "<span style=\"color:green\"> Linearity </span> - X & Y have a linear relationship  \n",
    "<span style=\"color:green\"> Independence </span> - Errors $e_i$ and $e_j$ must be independent of one another for $i \\neq j$  \n",
    "<span style=\"color:green\"> Normality </span> - Errors follow a normal distribution  \n",
    "<span style=\"color:green\"> Equality of Variances </span> - Erros should have roughly consistent pattern regardless of value of X\n",
    "## Error\n",
    "Coefficient of Determination = $R^2$  \n",
    "$R^2 = 1 - \\frac{SS_{tot}}{SS_{res}} $  \n",
    "$R^2 = 1 $->$ best$  \n",
    "$R^2 = 0 $->$ worst$\n",
    "## Regularization\n",
    "$R^2$ is the fraction of explained variance and can be used to predict the performance of a model\n",
    "### Overfitting in Linear Regression\n",
    "**Good properties**  \n",
    "- Low complexity\n",
    "- High bias/Low variance\n",
    "- Does not tend to overfit\n",
    "   \n",
    "**Danger Zone**\n",
    "- Including irrelevant features\n",
    "- $p$ (# of features) is too close to $n$ (# of observations) -> high variance\n",
    "- Correlated inputs -> redundant information\n",
    "- Numerically large coefficients ($\\beta$)\n",
    "\n",
    "## Ridge Regression\n",
    "$$ J(\\beta_0, \\beta_1) = RSS(\\beta_0, \\beta_1) + \\alpha\\beta^2 $$  \n",
    "Penalizes the model for having large coefficients  \n",
    "As $\\alpha$ increases $\\beta$ will decay\n",
    "- $\\alpha$ acts as a tuning parameter => fixed value   \n",
    "\n",
    "Ridge shrinks the regression coefficients\n",
    "## Lasso Regression\n",
    "$$ J(\\beta_0, \\beta_1) = RSS(\\beta_0, \\beta_1) + \\alpha|\\beta| $$  \n",
    "As $\\alpha$ increases $\\beta$ will decay even to the point of zero  \n",
    "Lasso shrinks the regression coefficients and may \"zero-out\" unimportant features\n",
    "#### Additional Considerations  \n",
    "Features should be standardized in regularized models so that the impact of $\\alpha$ is consistent\n",
    "\n",
    "## Elastic Net\n",
    "$$ J(\\beta_0, \\beta_1) = RSS(\\beta_0, \\beta_1) + \\alpha\\rho|\\beta| + \\frac{\\alpha(1-\\rho)}{2}\\beta^2 $$ \n",
    "$\\rho$ = Lasso ($L_1$) ratio  \n",
    "- For Lasso regression $\\rho = 1$  \n",
    "\n",
    "Allows for learning a sparse model where few of the weights are non-zero like Lasso, while still maintaining the regularization properties of Ridge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='eval'></a>\n",
    "# Evaluating Classifiers\n",
    "---\n",
    "## Baseline Accuracy\n",
    "The importance of calculating your baseline accuracy when building classifiers cannot be overstated. It is critical to know the baseline when you are evaluating a classifier using accuracy.\n",
    "> **Baseline Accuracy**: The accuracy that can be achieved by a model by simply guessing the majority class for every observation.  \n",
    "$$baseline = \\frac {majority\\_class_N}{total_N}$$\n",
    "\n",
    "## The confusion matrix\n",
    "** Threshold** - Point at which the model passes from positive to negative. Can be adusted to make the model more or less conservative   \n",
    "The confusion matrix is a table representing the performance of your model to classify labels correctly.\n",
    "\n",
    "|   |Predicted Negative | Predicted Positive |   \n",
    "|---|---|---|\n",
    "|**Actual Negative**  | True Negative (TN)  | False Positive (FP)  |\n",
    "|**Actual Positive** | False Negative (FN)  | True Positive (TP)  |\n",
    "\n",
    "In a binary classifier, the \"true\" class is typically labeled with 1 and the \"false\" class is labeled with 0  \n",
    "\n",
    "<span style=\"color:green\"> True Positive </span> - : A positive class observation (1) is correctly classified as positive by the model.  \n",
    "<span style=\"color:green\"> False Positive </span>: A negative class observation (0) is incorrectly classified as positive.  \n",
    "<span style=\"color:green\"> True Negative </span>: A negative class observation is correctly classified as negative.  \n",
    "<span style=\"color:green\"> False Negative </span>: A positive class observation is incorrectly classified as negative.\n",
    "\n",
    "<span style=\"color:blue\"> Recall </span> -> True Positive Rate -> Sensitivity  \n",
    "$$ TPR = \\frac{TP}{TP +FN} $$\n",
    "<span style=\"color:blue\"> Specificity </span> -> True Negative Rate\n",
    "$$ TNR = \\frac{TN}{TN +FP} $$\n",
    "<span style=\"color:blue\"> False Positive Rate </span>\n",
    "$$ FPR = \\frac{FP}{FP +TN} $$\n",
    "<span style=\"color:blue\"> Precision </span> -> Positive Predictive Power  \n",
    "How often you're right when you predict positive\n",
    "$$ PPP = \\frac{TP}{FP+TP} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='logreg'></a>\n",
    "# Logistic Regression\n",
    "---\n",
    "\n",
    "Logistic regression **is** a regression. It constructs a formula with our predictor variables and coefficients to estimate the *expected value* of the target variable. In a binary classification case this expected value is the probability of _y_ being one of the classes.\n",
    "\n",
    "\n",
    "$$E(y|X) = \\beta_0 + \\sum_{j}^p\\beta_jx_j$$\n",
    "\n",
    "Where:\n",
    "- $E(y|X)$ is the expected value (mean) of y given corresponding predictor values in matrix $X$\n",
    "- $\\sum_{j}^p$ are the predictors $j$ thru $p$ (columns) of the $X$ matrix\n",
    "- $\\beta_0$ is the intercept\n",
    "- $\\beta_j$ is the coefficient for the predictor $x_j$, the $j$th column in variable matrix $X$\n",
    "\n",
    "The goal of logistic regression is to find the best fitting model to describe the relationship between the characteristic of interest (dependent variable = response or outcome variable) and a set of independent (predictor or explanatory) variables. \n",
    "\n",
    "Logistic regression generates the coefficients (and in statsmodels the standard errors and significance levels) of a formula to predict a logit transformation of the probability of presence of the characteristic of interest.\n",
    "\n",
    "**Some examples of when logistic regression could be used:**\n",
    "- Predict whether or not a user will purchase a product given their demographic characteristics.\n",
    "- Predict the likelihood of a student being admitted to a college, given their scores and the characteristics of the college.\n",
    "- Diagnose a patient with a disease or not, given symptoms.\n",
    "- Predict whether a person will default on a loan and with what likelihood.\n",
    "\n",
    "**Logistic Regression Pros:**\n",
    "- Logistic regression is a classification algorithm that shares similar properties to linear regression\n",
    "- It is very fast and efficient and is by far the most common classification algorithm\n",
    "- The coefficients in a logistic regression model are interpretable (albeit somewhat complex): they represent the change in log-odds due to the input variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='svm'></a>\n",
    "# Support Vector Machine\n",
    "---\n",
    "### $O(n^2p) - O(n^3p)$\n",
    "\n",
    "If classes are <span style=\"color:green\"> linearly separable</span> , SVM finds the <span style=\"color:green\"> hyperplane </span> that separates the classes with <span style=\"color:green\"> maximum margin </span>  \n",
    "<span style=\"color:green\"> Hyperplane </span> - Straight line decision boundary between classes   \n",
    "<span style=\"color:green\"> Margin </span> - How close is the nearest point to the boundary -> space between decision boundary and nearest data point  \n",
    "\n",
    "Want to maximize margin!\n",
    "- SVM solves for hyperplane that should minimize error\n",
    "    - Larger margin creates a clear split between classes\n",
    "- Observations near the decision boundary are the most \"ambiguous\" and are easy to missclassify\n",
    "- SVM defines its fit using most ambiguous points\n",
    "\n",
    "## Maximum Margin Hyperplane\n",
    "If data is not linearly separable we still want to minimize margin width (w). We do this by introducing the **hinge loss**\n",
    "$$ [hinge\\ loss] = \\frac{1}{C}\\frac{1}{[margin\\ width]}$$\n",
    "\n",
    "The hyper-parameter $C$ controls the extent to which our SVM is tolerant to misclassification errors. It is sometimes called the \"soft-margin constant\". $C$ affects the strength of the \"penalty\", similar to the lambda terms in the Ridge and Lasso. \n",
    "\n",
    "The lower the value of $C$, the more misclassified observations errors are allowed. These misclassified points are known as \"slack variables\". Reducing the effect of errors on the loss function puts the emphasis on widening the margin.\n",
    "\n",
    "- Large C \n",
    "       - Narrow margin\n",
    "       - Less tolerant of misclassification\n",
    "       - Tends towards high variance $->$ overfit\n",
    "- Small C\n",
    "       - Wider margin\n",
    "       - More tolerant of misclassification \n",
    "       - Tends toward high bias $->$ underfit\n",
    "\n",
    "## Kernel Trick\n",
    "The \"kernel trick\" allows an SVM to classify non-linearly separable problems.\n",
    "\n",
    "The idea behind the kernel trick is that you can arbitrarily transform your observations that have no linear separability by putting them into a different \"dimensional space\" where they **DO** have linear separability, fit an SVM in that higher dimensional space, and then invert the transformation of the data and the model itself back into the original space.\n",
    "\n",
    "This is done by \"wrapping\" your predictors in a kernel function that transforms them into this higher dimensional space.\n",
    "\n",
    "SVM Pros\n",
    "- Exceptional performance\n",
    "- Robust to outliers\n",
    "- Effective in high dimensional data\n",
    "- Can work with non-linearities\n",
    "- Fast to compute even on non-linear (Kernal Trick)\n",
    "- Low risk of overfitting\n",
    "\n",
    "SVM Cons\n",
    "- Blackbox\n",
    "- Can be slow on large data sets\n",
    "\n",
    "## When to use SVM vs. Logistic Regression\n",
    "**If there are more feature than training samples:**\n",
    "    Use logistic regression or SVM without a kernel (\"linear kernel\")\n",
    "    \n",
    "**If there are about 10 times as many samples as features:**\n",
    "    Use SVM with a Gaussian kernel\n",
    "    \n",
    "**If there are many more training samples than features:**\n",
    "    Spend time feature engineering, then use logistic regression or SVM\n",
    "    without a kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='knn'></a>\n",
    "# K-Nearest Neighbors\n",
    "---\n",
    "### $O(log(n) * p) - O(n^2 * p)$\n",
    "\n",
    "Estimates a value (regression) or class membership (classification) by finding the observations in its training data that are \"nearest\" to observation.  \n",
    "Distance is calculated using euclindean distance.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='carts'></a>\n",
    "# Classification and Regression Trees\n",
    "---\n",
    "### $O(n log n * p) - O(n^2 log n * p)$\n",
    "They are **sequential** because they predict based on a sequence of decisions, and **hierarchical** because some decisions occur earlier, or are more important, than others.\n",
    "\n",
    "Decision Trees are also **non-parametric**, meaning they don't make any assumptions about the underlying data.\n",
    "\n",
    "They can be represented as a **Directed Acyclic Graph**: basically a flow chart where observations only go in one direction (_directed_) and cannot flow back on themselves (_acyclic_).\n",
    "\n",
    "Decision Trees are built by a **greedy** algorithm that determines, at each **internal node** of the tree, what question will split the observations best. Questions that divide the data well are those that maximize the **purity** in the resulting nodes. When a node is 100% pure we call it a **leaf node**, and that branch of the tree stops growing.\n",
    "\n",
    "Common measures of purity are the **Gini coefficient** and **Entropy**. They're mathematically distinct, but you don't need to worry about the exact difference between them. They're implemented for you in `sklearn`.\n",
    "\n",
    "A Decision Tree will continue growing until all leaf nodes are pure. This is overfitting! To stop Decision Trees from overfitting, you will use a kind of stopping criterion: either the maximum depth of your tree or the minimum number of samples in a node before a split is made.\n",
    "\n",
    "## Levels of a CART\n",
    "- <span style=\"color:green\"> Root Node </span> - Primary question\n",
    "- <span style=\"color:green\"> Interior Node </span> - Filtering question\n",
    "- <span style=\"color:green\"> Leaf </span> - Outcome\n",
    "\n",
    "## Generalizing Purity\n",
    "<span style=\"color:green\"> Impurity </span> measures for a node with data D   \n",
    "Decision trees split data at each node  \n",
    "For each split we can calculate purity    \n",
    "$purity\\ of\\ class\\ i = p(class\\ i| data\\ at\\ node)$\n",
    "$$ \\text{Entropy} = -\\sum_{i=1}^{classes} p(i\\;|\\;t) \\;log_2( p(i\\;|\\;t) ) $$\n",
    "We can use entropy to help us determine which is the best criteria split for our data, using it's output we can calculate information gain\n",
    "- Non-negative \n",
    "- Entropy will be close to 0 when class balance close to 0 (ie: %98 Class 1 / %2 Class2 or vice-versa)\n",
    "- With multiple classes are not close to 0, entropy will be larger\n",
    "$$ \\text{Gini} = 1 - \\sum_{i=1}^{classes} p(i\\;|\\;t)^2 $$\n",
    "\n",
    "We use gini critereon to measure the \"purity\" of a split.  Gini we can also be used to calculate information gain\n",
    "- Non-negative\n",
    "- Ranges from 0 to .5\n",
    "- Closer to .5 with equal splits.\n",
    "- Not as sensitive as Entropy\n",
    "- More efficient to calculate than log2\n",
    "\n",
    "For binary classification\n",
    " - Worse case, purity = 0.5\n",
    " - Best case, purity = 1.0\n",
    "\n",
    "## Information Gain\n",
    "Information Gain is a way for us to figure out how much information is contained within the resulting X from $ P(y\\ |\\ X\\ =\\ condition) $.\n",
    "$$gain = I(parent) - \\sum_{child}\\frac{N_j}{N}I(child_j)$$\n",
    "Where:\n",
    "- $I$ is the impurity measure, \n",
    "- $N_j$ is the number of observations at child node $j$\n",
    "- $N$ is the number of obserbvations at the parent node\n",
    "\n",
    "## Decision Tree  \n",
    "<span style=\"color:green\"> Hierarchical </span> - Sequence of \"if this then that\" conditions   \n",
    "<span style=\"color:green\"> Non-parametric </span> - No $\\beta$ coefficients  \n",
    "- No assumtpion on distribution\n",
    "    \n",
    "Advantages\n",
    "- Simple to understand\n",
    "- Requires little data preparation\n",
    "- Able to handle both numerical and categorical data\n",
    "- Possible to validate a model using stat testing\n",
    "- Performs well on large datasets\n",
    "- Once trained can be implemented on hardware and has extremely fast (real-time) execution\n",
    "\n",
    "Disadvantages\n",
    "- Locally optimal\n",
    "- Prone to overfitting\n",
    "- Concepts that are hard to learn (parity or multiplexer problems)\n",
    "- Decision Trees can be biased if some classes dominate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='ensemble'></a>\n",
    "# Ensemble Method\n",
    "---\n",
    "## Characteristics\n",
    "<span style=\"color:green\"> Accuracy </span> - Baseline classifier must outperform random guessing  \n",
    "<span style=\"color:green\"> Diversity </span> - Missclassification must occur on different training sets  \n",
    "A base classifier may not perform well\n",
    "- Statistical - Not enough data . \n",
    "- Computational  \n",
    "- Representational - Data exists in a way where the function doesn't fit well\n",
    "\n",
    "## Hypothesis Space\n",
    "Goal is to make predictions of true classifier $f$ by learning the classifier $k$ . \n",
    "\n",
    "## Types of Ensemble Techniques\n",
    "<span style=\"color:green\"> Averaging </span> - Build several estimates and average their predictions   \n",
    "<span style=\"color:green\"> Boosting </span> - Base estimates are built sequentially and one tries to reduce the bias of the combined estimator  \n",
    "<span style=\"color:green\"> Bagging </span> - Method that involves manipulating the training set by resampling. Starts with strong learners and reduce their variance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='class review'></a>\n",
    "# Classification Method Review\n",
    "---\n",
    "|   |KNN | SVC | DT | LogReg |   \n",
    "|:---|:---:|:---:|:---:|:---:|\n",
    "|**Feature Importance**  | N | N | Y | Y |\n",
    "|**Fast**  | ~ | N | Y | Y |\n",
    "|**Sparse**  | Y | Y | Y | Y |\n",
    "|**Mixing**  | Y | N | Y | - |\n",
    "|**Parametric**  | N | Y | - | Y |\n",
    "|**Splits**  | Y | Y | Y | N |\n",
    "|**Scaling** | Y | Y | N | Y |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='boosting'></a>\n",
    "# Boosting\n",
    "---\n",
    "<span style=\"color:green\"> Boosting </span> - Trees are grown sequentially. $2^{nd}$ tree tries to optimize quesses from $1^{st}$ tree\n",
    "\n",
    "Boosting is another ensemble method with a different approach to bagging. Boosting takes a weak base learner and tries to make it a strong learner by re-training it on the misclassified samples. Boosting aims to **reduce bias**\n",
    "\n",
    "1. **Base model fitting is an iterative procedure**: it cannot be run in parallel.\n",
    "- **Weights assigned to observations indicating their \"importance\"**: samples with higher weights are given higher influence on the total error of the next model, prioritizing those observations.\n",
    "- **Weights change at each iteration with the goal of correcting the errors/misclassifications of the previous iteration**: the first base estimator is fit with uniform weights on the observations.\n",
    "- **Final prediction is typically constructed by a weighted vote**: weights for each base model depends on their training errors or misclassification rates.\n",
    "\n",
    "## Pros and cons of boosting\n",
    "\n",
    "**Pros**\n",
    "- Achieves higher performance than bagging when hyper-parameters tuned properly.\n",
    "- Can be used for classification and regression equally well.\n",
    "- Easily handles mixed data types.\n",
    "- Robustness to outliers in output space (via robust loss functions)\n",
    "\n",
    "**Cons**\n",
    "- Difficult and time consuming to properly tune hyper-parameters.\n",
    "- Cannot be parallelized like bagging (bad scalability when huge amounts of data).\n",
    "- More risk of overfitting compared to bagging.\n",
    "\n",
    "## AdaBoost\n",
    "<span style=\"color:green\"> AdaBoost </span> - Classification predictions for y using predictor matrix X  \n",
    "$$ AdaBoost(X) = sign\\left(\\sum_{t=1}^T \\alpha_t h_t(X)\\right)$$\n",
    "<span style=\"color:green\"> $T$ </span> - set of \"weak learners\"  \n",
    "<span style=\"color:green\"> $\\alpha_t$ </span> - contribution weight for weak learner $t$  \n",
    "<span style=\"color:green\"> $h_t(X)$ </span> - prediction of weak learner $t$  \n",
    "<span style=\"color:green\"> $y$ </span> - binary **with values -1 and 1**\n",
    "\n",
    "**Core Principle**  \n",
    "Fit a sequence of weak learners on repeatedly modified versions of the data  \n",
    "Predictions are then combined through a weighted majority vote (sum) to produce a final prediction\n",
    "\n",
    "All training examples start with equal importance weighting. When we finish training a classifier, we update the importance weighting of the classifier itself represented by alpha $\\alpha$\n",
    "\n",
    "**Training Example Weights**  \n",
    "Adaboost sets up a weight vector on the observations ($D_t$) where $t$ is the current model iterations, $D_t$ is the probability distribution that determines how likely it is a given observation will be selected . $\\alpha$ weighting of the last fit estimator is used in the equation for the weighted distribution.\n",
    "$$D_{t+1}(i) = D_t(i)e^{-\\alpha_iy_ih_i(x_i)}$$\n",
    "$i \\rightarrow$ vector of observation  \n",
    "$x_i \\rightarrow$ observation at the index  \n",
    "$y_i \\rightarrow$ target  \n",
    "$h_i \\rightarrow$ previous model fit in boosting chain\n",
    "\n",
    "To Normalize:  \n",
    "$$D_{t+1}(i) = \\frac{D_{t+1}(i)}{\\sum D_{t+1}(i)}$$\n",
    "\n",
    "## Gradient Boosting\n",
    "<span style=\"color:green\"> Gradient Boost </span> - Fits subsequent models to the residuals of the last model  \n",
    "Method:  \n",
    "1. Fit a model $F$ to the data.\n",
    "2. Look at the difference between our observed $y$ and our model $F$. (The $y_i - F(x_i)$ can be thought of as residuals!)\n",
    "3. Fit a second model $F_2$ to (roughly) the residuals $y_i - F(x_i)$.\n",
    "4. Aggregate your model $F$ and $F_2$. While we won't get into the details here, we can interpret residuals as negative gradients. By doing this, we can apply our gradient descent algorithm to optimize our loss and generalize this to many loss functions.  \n",
    "\n",
    "\n",
    "## The difference between the AdaBoost and Gradient Boosting?\n",
    "- AdaBoost is about re-weighting the preceding model's errors in subsequent iterations.\n",
    "- Gradient Boosting is about fitting subsequent models to the residuals of the last model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stochastic Gradient Descent\n",
    "---\n",
    "### $O(np)$\n",
    "**Gradient Descent** is an iterative method used to identify the optimal value of parameters by optimizing an objective function.\n",
    "\n",
    "**Stochastic Gradient Descent** has been successfully applied to large-scale and sparse machine learning problems often encountered in _text classification_ and _natural language processing_. Given that the data is sparse, the classifiers in this module easily scale to problems with more than 10^5 training examples and more than 10^5 features.\n",
    "\n",
    "The advantages of Stochastic Gradient Descent are:\n",
    "- Efficiency.\n",
    "- Ease of implementation (lots of opportunities for code tuning).\n",
    "\n",
    "The disadvantages of Stochastic Gradient Descent include:\n",
    "- SGD requires a number of hyperparameters such as the regularization parameter and the number of iterations.\n",
    "- SGD is sensitive to feature scaling.\n",
    "\n",
    "## SGDClassifier\n",
    "**SGDClassifier** implements a plain stochastic gradient descent learning routine which supports different loss functions and penalties for classification.  \n",
    "\n",
    "The gradient of the loss is estimated each sample at a time and the model is updated along the way with a decreasing strength schedule (aka learning rate). SGD allows minibatch (online/out-of-core) learning. For best results using the default learning rate schedule, the data should have zero mean and unit variance.\n",
    "\n",
    "This implementation works with data represented as dense or sparse arrays of floating point values for the features. The model it fits can be controlled with the loss parameter. By default, it fits a linear support vector machine (SVM).\n",
    "\n",
    "SGDClassifier supports the following loss functions:\n",
    "- loss=\"hinge\": (soft-margin) linear Support Vector Machine\n",
    "- loss=\"modified_huber\": smoothed hinge loss\n",
    "- loss=\"log\": logistic regression\n",
    "\n",
    "\n",
    "## SGDRegressor\n",
    "**SGDRegressor** implements a plain stochastic gradient descent learning routine which supports different loss functions and penalties to fit linear regression models. \n",
    "\n",
    "SGDRegressor is well suited for regression problems with a large number of training samples (> 10.000), for other problems we recommend Ridge, Lasso, or ElasticNet.\n",
    "\n",
    "SGDRegressor supports the following loss functions:\n",
    "- loss=\"squared_loss\": Ordinary least squares\n",
    "- loss=\"huber\": Huber loss for robust regression\n",
    "- loss=\"epsilon_insensitive\": linear Support Vector Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes\n",
    "---\n",
    "### $O(np)$\n",
    "\n",
    "Naive Bayes models can be used for large scale classification problems for which the full training set might not fit in memory. It has a *partial_fit* method that can be used incrementally. All naive Bayes classifiers support sample weighting.\n",
    "\n",
    "### Multinomial\n",
    "- Suitable for discrete data\n",
    "- Normally requires integer feature counts. However, fractional counts such as tf-idf may also work\n",
    "\n",
    "Is one of the two classic naive Bayes variants used in text classification (where the data are typically represented as word vector counts, although tf-idf vectors are also known to work well in practice)\n",
    "\n",
    "### Bernoulli\n",
    "- Suitable for discrete data \n",
    "- Designed for binary/boolean features\n",
    "\n",
    "This class requires samples to be represented as binary-valued feature vectors; if handed any other kind of data, a BernoulliNB instance may binarize its input (depending on the binarize parameter).  \n",
    "\n",
    "The decision rule for Bernoulli naive Bayes is based on\n",
    "$$P(x_i \\mid y) = P(i \\mid y) x_i + (1 - P(i \\mid y)) (1 - x_i)$$\n",
    "\n",
    "It explicitly penalizes the non-occurrence of a feature $i$ that is an indicator for class $y$, where the multinomial variant would simply ignore a non-occurring feature.\n",
    "\n",
    "### Gaussian\n",
    "- Can perform online updates to model parameters via partial_fit method\n",
    "\n",
    "### Pros\n",
    "- NLP\n",
    "- Partial fitting\n",
    "- Sparse data\n",
    "\n",
    "### Cons\n",
    "- No probabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='clustering'></a>\n",
    "# Clustering\n",
    "---\n",
    "<span style:\"color:green\"> Clustering </span> - Unsupervised learning to find groups that exist in the data  \n",
    "\n",
    "We use **unsupervised learning** methods when we don't have labeled data. No true targets to predict, dervise likely categories from structures in our data.\n",
    "\n",
    "### Uses\n",
    "- Find items with similar behaviour\n",
    "- Market segmentation\n",
    "- Understand complex systems\n",
    "- Discover meaning categories for your data\n",
    "- Reduce dimensions of your problem\n",
    "- Preprossessing! Create labels for supervised learning\n",
    "\n",
    "### Properties\n",
    "- No true targets\n",
    "- We apply structur to data quantitatively based on specific creiteria\n",
    "- Predictions of label are based on structure of data\n",
    "\n",
    "<a id='kmeans'></a>\n",
    "## K-Means Clustering\n",
    "<span style=\"color:green\"> K </span> - # of clusters -> chosen in advance  \n",
    "<span style=\"color:green\"> Means </span> - mean points of the K clusters  \n",
    "**Goal** - split the data into groups such that the total sum of squared distances from each point to the mean point of the cliusters is minimized  \n",
    "Takes the entire dataset & iterates over its observations to determine clusters based around center points known as <span style=\"color:green\"> centroids </span>  \n",
    "Sensitive to outliers & centroid initialization \n",
    "\n",
    "**Choosing K**\n",
    "- Randomly\n",
    "- Manually\n",
    "- Special KMeans++ method in Sklearn\n",
    "\n",
    "Metrics: inertia & the silhouette coefficient  \n",
    "<span style=\"color:green\"> Inertia </span> - sum of squared errors for each cluster\n",
    "- low intertia - dense cluster\n",
    "- ranges from 0 to very high values\n",
    "\n",
    "<span style=\"color:green\"> Silhouette Coefficient </span> - measure of how far apart clusters are\n",
    "- high silhouette score - clusters are well separated\n",
    "- ranges from -1 to 1\n",
    "\n",
    "**Conclusion**  \n",
    "Similar to KNN  \n",
    "Iteratively finds labels given K  \n",
    "Easy to implement in sklearn  \n",
    "Sensitive to shape, scale of data  \n",
    "Optimal K is hard to find\n",
    "\n",
    "<a id='dbscan'></a>\n",
    "## DBSCAN\n",
    "<span style=\"color:green\"> DBSCAN </span> - Density Based Spatial Clustering of Application with Noise  \n",
    "Clusters of high density are separated by clusters of low density . \n",
    "<span style=\"color:green\"> Density </span> - DBSCAN uses a neighbor based polling approach. Ideal for clusters that have similar variance  \n",
    "<span style=\"color:green\"> Noise </span> - Not every point will be associated with a cluster  \n",
    "**Parameters**\n",
    "- <span style=\"color:green\"> Min Points </span> - Min # of points required to for a cluster\n",
    "- <span style=\"color:green\"> Epsilor </span> - Max. spanning distance that a point can be from the polling point in order to be recruited to the cluster\n",
    "\n",
    "**Advantages**  \n",
    "Clusters can be any shape or size  \n",
    "No need to choose # of clusters  \n",
    "\n",
    "**Disadvantages**\n",
    "More parameters to choose  \n",
    "Doesn't work with clusters or varying density  \n",
    "Not every point is assigned to a cluster!\n",
    "\n",
    "**Key Outputs**  \n",
    "<span style=\"color:green\"> Core samples </span> - Points which the algorithm initially finds and searches around the neighborhood to form the cluster  \n",
    "<span style=\"color:green\"> Labels </span> - The cluster labels\n",
    "\n",
    "<a id='hierarchy'></a>\n",
    "## Hierarchical Clustering\n",
    "Builds hierarchies of links that ultimately form clusters. Displayed in a <span style=\"color:green\"> dendrogram </span> -> graph that displays all of these links in a hierarchical manner  \n",
    "**How does it differ from K-Means**\n",
    "- To find clusters we cut the graph at a cutoff of our choosing  \n",
    "- Merges similar data points -> don't have to pre-set K  \n",
    "- More beneficial for smaller datasets  \n",
    "- Binary or dummy variables  \n",
    "\n",
    "**Types of Hierarchical Clustering**  \n",
    "<span style=\"color:green\"> Agglomerative </span> - What two points are similar -> form cluster  \n",
    "<span style=\"color:green\"> Divisive </span> - Starts with 1 cluster -> Splits base don what is the furthest thing away\n",
    "\n",
    "<span style=\"color:green\"> Cophenetic Correlation Coefficient </span> - Measures the height of the dendrogram where the last two branches merge.\n",
    "- Tells us how well dendrogram measured the distance between data points in original dataset\n",
    "- Higher is better\n",
    "- Between 0 and 1\n",
    "\n",
    "**Cluster Evaluation**  \n",
    "Visually evaluating clusters\n",
    "- Plot to see where they are and if they make sense \n",
    "\n",
    "Silhouette Score\n",
    "- <span style=\"color:green\">Cohesion </span> - clustering effectiveness within a cluster\n",
    "- <span style=\"color:green\">Separation </span> - clustering effectiveness between clusters\n",
    "- Ranges from -1 to 1\n",
    "- Want deparation to be high & cohesion to be low\n",
    "- Negative SS => cluster radius is larger than space between clusters.\n",
    "    - Non-assigned clusters are more similar than assigned clusters\n",
    "- <span style=\"color:green\">Homogeneity</span> - Requires real labels\n",
    "    - How good are your clusters based on the \"true\" clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='time'></a>\n",
    "# Time Series & Datetime\n",
    "---\n",
    "<span style=\"color:green\">Timeseries</span> - series of datapoints listed at successive points in time\n",
    "## Time Series Modeling\n",
    "<span style=\"color:green\">Stationarity</span> - time series has constant mean & variance. Many models will assume stationarity  \n",
    "**Decomposition**  \n",
    "$$ Y_t = T_t + S_t + C_t + \\varepsilon_t$$\n",
    "- <span style=\"color:green\">$Y_t$</span> - observed value at time $t$  \n",
    "- <span style=\"color:green\">$T_t$</span> - trend component, long-run behavior  \n",
    "- <span style=\"color:green\">$S_t$</span> - seasonality component, periodic fluctuations  \n",
    "- <span style=\"color:green\">$C_t$</span> - cyclical component, non-periodic fluctuations\n",
    "    - often included in trend component\n",
    "- <span style=\"color:green\">$\\varepsilon_t$</span> - noise component $->$ want this to be stationary\n",
    "    - want to model the noise\n",
    "> Decomposition above is additive; can also be multiplicative.\n",
    "\n",
    "<span style=\"color:green\">Autocorrelation</span> - correlation between a time series and a lagged version of itself   \n",
    "Time series assume obserations are dependent\n",
    "$$ Corr(Y_t, Y_{t+k}) = \\frac{Cov(Y_t, Y_{t+k})}{\\sqrt{Var(Y_t)Var(Y_{t+k})}} $$\n",
    "Autocorrelation tells how strongly a time value is dependent on previous values\n",
    "\n",
    "<span style=\"color:green\">Partial Autocorrelation (PACF)</span> - correlation at a givn lag controlling for the effect of previous lags  \n",
    "<span style=\"color:green\">Differncing </span> - The most common way to make a timeseries stationary is to perform \"differencing\". This procedure converts a timeseries into the difference between values:\n",
    "$$\\Delta y_t = y_t - y_{t-1} $$\n",
    "This removes trends in the timeseries and ensures that the mean across time is zero. In most cases there will only be a need for a single differencing, although sometimes a second difference (or even more) will be taken to remove trends.\n",
    "\n",
    "## Autoregressive (AR) models\n",
    "<span style=\"color:green\">Autoregressive (AR)</span> models use data from previous time-points to predict the next time-point. These are essentially regression models where the predictors are previous timepoints of the outcome.\n",
    "\n",
    "Typically, AR models are denoted `AR(p)`, where _p_ indicates the number of previous time points to incorporate. `AR(1)` is the most common.  \n",
    "\n",
    "In an autoregressive model we learn regression coefficients on the features that are the previous _p_ values.  \n",
    "\n",
    "We can build autoregressive models using the `ARMA` class from statsmodels. \n",
    "\n",
    "## Moving Average (MA) models\n",
    "<span style=\"color:green\">Moving average</span> models take previous _error terms_ as inputs. They predict the next value based on deviations from previous predictions. We have an order term, _q_, and we refer to our model as `MA(q)`\n",
    "\n",
    "In the simpler fitting procedures, a model is iteratively fit, errors are computed, then refit, over and over again until the parameters on the errors converge.\n",
    "\n",
    "MA includes the mean of the time series. The behavior of the model is therefore characterized by random jumps around the mean value.\n",
    "\n",
    "In an `MA(1)` model, there is one coefficient on the error of our previous prediction impacting our estimate for the next value in the timeseries.\n",
    "\n",
    "## ARMA and ARIMA models\n",
    "<span style=\"color:green\">ARMA</span> models combine the autoregressive models and moving average models. We combine both, parameterizing the behavior of the model with `p` and `q` terms corresponding to the `AR(p)` model and `MA(q)` model.\n",
    "\n",
    "Autoregressive models slowly incorporate changes in preferences, tastes, and patterns. Moving average models base their prediction not on the prior value but the prior error, allowing us to correct sudden changes based on random events - supply, popularity spikes, etc.\n",
    "\n",
    "<span style=\"color:green\">ARIMA</span> is just like the `ARMA(p, q)` model, but instead of predicting the value of the series it predicts the _differenced_ series or changes in the series. The order of differencing is set by an _d_ term as in `ARIMA(p, d, q)`, or alternatively you can just fit an `ARMA(p, q)` model on a differenced timeseries.\n",
    "\n",
    "Recall the pandas **diff** function. This computes the difference between two consecutive values. In an ARIMA model, we attempt to predict this difference instead of the actual values.\n",
    "\n",
    "$$y_t - y_{(t-1)} = ARMA(p, q)$$\n",
    "\n",
    "Timeseries are assumed to be \"stationary\" when modeling. This handles the stationarity assumption: instead of detrending or differencing manually, the model does this via the differencing term.\n",
    "\n",
    "## How to choose the right `p` and `q` parameters\n",
    "These rules apply to the ACF and PACF plots of differenced timeseries rather than the original timeseries (the exception being if your timeseries is stationary and does not require differencing):\n",
    "\n",
    "- If the PACF has a sharp cutoff and the lag-1 ACF value is positive then choose an AR(x) term where x is the lag in the PACF after the cutoff.\n",
    "- If the ACF has a sharp cutoff and the lag-1 ACF value is negative, choose an MA(x) term where x is the lag in the ACF after the cutoff.\n",
    "- If both the ACF and PACF show a gradual decay, and ARMA model is likely appropriate as opposed to the AR or MA alone.\n",
    "\n",
    "Context 1 above corresponds to timeseries that are \"underdifferenced\" as indicated by a positive autocorrelation at lat 1. Likewise, context 2 is \"overdifferenced\" as indicated by the negative autocorrelation.\n",
    "\n",
    "In general, you should try to choose an AR or MA model alone as opposed to an ARMA model. The AR and MA terms can work against each other in the model and create an overly-complex representation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='neural nets'></a>\n",
    "# Neural Networks\n",
    "---\n",
    "|Loss Function | Activation Function | Output Dim | Problem Type |   \n",
    "|--------------|---------------------|:----------:|--------------|\n",
    "|MSE, MAE| Linear | 1 | Regression |\n",
    "|Binary Cross-entropy| Sigmoid| 1 | Binary Class|\n",
    "|Categorical Cross-entropy|Softmax, tanh | N | N-Label Class|\n",
    "\n",
    "\n",
    "### Features\n",
    "Normalized data on scale between 0 and 1 (or -1 and 1)  \n",
    "Don't worry about shape\n",
    "### Outputs\n",
    "Regression - one output is fine  \n",
    "Classification - one out per class is a good idea\n",
    "\n",
    "## Neurons\n",
    "Neural networks are built up of neurons that are linked together. Each takes in either the original input features or some transformed version of them and puts out a value (or set of values)    \n",
    "<span style=\"color:green\">Neurons</span> are a combination of:\n",
    "- <span style=\"color:green\">Bias</span> term - a constant of $\\beta_0$ term in a linear regression\n",
    "- The input term they've recieved multiplied by a <span style=\"color:green\">weight</span>\n",
    "- Weights are derived by trial and error\n",
    "\n",
    "## Hidden Layers  \n",
    "Layers that are neither the input or the output  \n",
    "- Can have any # of neurons\n",
    "- Can be of any # in your model\n",
    "\n",
    "Each neuron in a layer recieves the same weight  \n",
    "Each neuron transforms data in a different way\n",
    "![](../../../GA_DSI/Lectures/lesson-intro-to-neural-networks/images/neuralnet.png)\n",
    "\n",
    "## Activation\n",
    "Neurons have an activation function that transforms output. Each neuron is a sum of the weighted activations of neurons that feed into it plus a \"bias\" value, all fed through a final activation function.\n",
    "\n",
    "$$ a_j^i = \\sigma \\left( \\sum_k w_{jk}^i a_k^{i-1} + b_j^i \\right)$$\n",
    "There is a decent amount going on in this equation. We will examine the pieces.\n",
    "\n",
    "- $a_j^i$ represents the activation of the $j$th neuron in the $i$th layer. Note that the superscript corresponds to the layer number and the subscript corresponds to the neuron number within the layer.\n",
    "- $a_k^{i-1}$ is the activation of the $k$th neuron in the $i-1$th layer.\n",
    "- $\\sigma$ represents an \"activation function\". More on this later, but it is a function that can transform the activation of neurons. The simplest activation function is the linear activation, $f(x) = x$.\n",
    "- $w_{jk}^i$ represents the weight of the activation in the $k$th neuron in the $i-1$ layer to the $j$th neuron in the $i$th layer. So, $j$ is the destination neuron in the $i$ layer. $k$ is the departure neuron in the previous layer.\n",
    "- $b_j^i$ is the \"bias\" of the $j$th neuron in the $i$th layer. The bias adds a constant to the value of the activation.\n",
    "\n",
    "![](../../../GA_DSI/Lectures/lesson-intro-to-neural-networks/images/activation.png)\n",
    "\n",
    "Neurons also have an activation function that transforms the output in a certain way. Some common examples are:\n",
    "- [ReLU](https://en.wikipedia.org/wiki/Rectifier_(neural_networks): Also known as a Rectified Linear Unit, this turns the output to 0 if the output would be less than 0 (i.e., take the output and feed it through $f(y) = max(0, y)$). This means that the neuron is activated when its output is positive and not activated otherwise. This has the intuitive effect of turning a neuron \"on\" in certain cases and off in other cases.\n",
    "- [Softmax](https://en.wikipedia.org/wiki/Softmax_function): Used frequently at the output layer, this essentially \"squishes\" a bunch of inputs into a normalized scale of 0-1, which is great for creating something akin to a probability of falling into a given class. \n",
    "- [Sigmoid or Logistic](https://en.wikipedia.org/wiki/Logistic_function): Much like how we transformed the linear regression model to change the output to a zero or one through the use of a logistic or sigmoid function, we can do the same as an activation to squash the output to a scale between 0 and 1. \n",
    "\n",
    "\n",
    "## Topology\n",
    "Much like hyperparameters in other machine learning models, we're going to use a combination of experience, research, and exploration to come up with a topology that best suits our unique problem. One good place to start out is to (if you have a smaller set of input features) is a network with:\n",
    "1. The input layer\n",
    "2. One hidden layer with a number of neurons equal to the number of inputs\n",
    "3. One output layer with the appropriate activation function (softmax if you have a classification problem, no activation (or what's known as the identity function ($f(x) = x$) if you have a regression problem\n",
    "\n",
    "## Single Layer and Multilayer Perceptrons (SLP and MLP)\n",
    "\n",
    "The types of neural networks that we have discussed so far are known as perceptrons. A single layer perceptron **has no hidden layers** and is just a function of the inputs, weights, a bias term, and an activation function:\n",
    "\n",
    "![](../../../GA_DSI/Lectures/lesson-intro-to-neural-networks/images/slp.png)\n",
    "\n",
    "Multilayer perceptrons (MLP) have 1 or more hidden layers in addition to their input and output layers. While SLPs are easiest to consider in an abstract sense, MLPs tend to be much more accurate and useful in practice.\n",
    "## Training\n",
    "### Forward & Back Propagation\n",
    "#### Forward Propagation\n",
    "\n",
    "Forward Propagation is straightforward -- either in batches or as individual observations, pass the training data through the network, applying all the weights, biases, and activation functions as usual. At this point, you should have actual and predicted values.\n",
    "\n",
    "#### Backpropagation\n",
    "\n",
    "What we want to do here is:\n",
    "\n",
    "1. See how far off we were from the truth using the loss function\n",
    "2. Identify which weights in our network are most responsible for how far we are off\n",
    "3. Change all of the weights to make our model more accurate, changing the weights that are \"the worst\" the most\n",
    "\n",
    "This is known as **Backpropagation** -- we are taking the errors we see in our model (as it stands currently) and are distributing them backwards to the rest of the layers. \n",
    "\n",
    "What we'll do is train our data in a number of full passes known as **epochs**. As modelers, we'll choose a number of epochs to train our model, essentially choosing a value to stop where we see no additional change in the accuracy of our models. \n",
    "\n",
    "## Regularization\n",
    "\n",
    "### Method 1: L1 & L2\n",
    "Just like with linear and logistic regression, we can use L1 and L2 regularization on our neural networks.\n",
    "\n",
    "### Method 2: Dropout\n",
    "Dropout will turn off a random percentage of neurons in each pass (user-defined). This prevents each layer from fitting too strongly to a given input and therefore wards off overfitting.\n",
    "\n",
    "The intuition behind dropout is that, since each node has a probability of disappearing at any time, the neural network is disincentivized from allocating too much power to any one weight. It has a similar effect as imposing an L2 penalty: the magnitude of our weights shrinks.\n",
    "\n",
    "**Inverted Dropout**\n",
    "In order to avoid any issues with the expected values of our nodes changing, we adjust our results accordingly by a method called inverted dropout.\n",
    "\n",
    "If we have a hidden layer with 100 nodes and each node has a 80% probability of being \"staying turned on,\" we only have 80% of those inputs to our node. As a result, we expect that the combined input to our node $z = b_0 + \\sum_{i=1}^pw_ix_i$i will be off by about 20%. (Those interested in probability and research might note that the Binomial distribution is a very convenient model for neural networks and dropout.)\n",
    "\n",
    "When using inverted dropout, we adjust zz by the \"keeping probability.\"\n",
    "\n",
    "$$\n",
    "\\begin{eqnarray*}\n",
    "z_{original} &=& b_0 + \\sum_{i=1}^pw_ix_i \\\\\n",
    "\\Rightarrow z_{dropout} &=& b_0 + \\sum_{i\\in\\{included\\_nodes\\}}w_ix_i \\\\\n",
    "\\Rightarrow z_{inverted\\_dropout} &:=& z_{dropout} / 0.8 \\\\\n",
    "\\end{eqnarray*}\n",
    "$$\n",
    "\n",
    "### Method 3: Early Stopping\n",
    "Early stopping does exactly what its name implies: it stop the training process early. Instead of continuing training through every epoch, once the validation error begins to increase, our algorithm stops because it has (in theory) found the minimum for the validation loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
